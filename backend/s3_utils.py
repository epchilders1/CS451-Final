import os
import boto3
import logging
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv
load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

bucket_name = os.getenv('AWS_BUCKET_NAME')
region = os.getenv('AWS_BUCKET_REGION')
s3_key = os.getenv('AWS_ACCESS_KEY_ID')
s3_secret = os.getenv('AWS_SECRET_ACCESS_KEY')

def upload_files_to_s3(bucket_name: str, file_paths: List[str]):
   
    try:
        # Boto3 automatically uses environment variables (AWS_ACCESS_KEY_ID, etc.)
        s3_client = boto3.client('s3')
        logger.info(f"Attempting to upload {len(file_paths)} files to S3://{bucket_name}/")

        for local_file_path in file_paths:
            p = Path(local_file_path)
            if not p.exists():
                logger.warning(f"File not found, skipping: {local_file_path}")
                continue

            # Key is the path within the S3 bucket
            s3_key = f"{p.name}"

            s3_client.upload_file(str(p), bucket_name, s3_key)
            logger.info(f"Successfully uploaded {p.name} to {s3_key}")
            
    except Exception as e:
        logger.error(f"Failed to upload files to S3: {e}")
        # Re-raise the exception to fail the GitHub Action
        raise

def main():
    """Example usage, run only when models are ready."""
    # This utility is designed to be called by the GitHub Action workflow.
    # Replace with your actual bucket name.
    
    # List all files generated by the train_models.py script
    files_to_upload = [
        './data/weekly_features.csv',
        './models/logistic_regression_model.pkl',
        './models/random_forest_model.pkl',
        './models/xgboost_model.pkl',
        './models/lightgbm_model.pkl',
        './models/feature_importance.json',
        './models/latest_prediction.json'
    ]

    upload_files_to_s3(bucket_name, files_to_upload)

if __name__ == '__main__':
    # When running locally, you must have AWS credentials configured 
    # (e.g., via AWS CLI or environment variables)
    main()
    pass